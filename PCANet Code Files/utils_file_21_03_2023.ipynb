{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_IM3Aw4GhiO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "def reshape_dataset(train, test):\n",
        "    def channels_last(X):\n",
        "        X = np.swapaxes(X, 1, 2)\n",
        "        X = np.swapaxes(X, 2, 3)\n",
        "        return X\n",
        "\n",
        "    X_train, y_train = train._datasets[0], train._datasets[1]\n",
        "    X_test, y_test = test._datasets[0], test._datasets[1]\n",
        "    X_train, X_test = channels_last(X_train), channels_last(X_test)\n",
        "\n",
        "    print(\"Dimensions of the MNIST dataset after changing the reshaping---\")\n",
        "    print(f\"X_train: {X_train.shape}\")\n",
        "    print(f\"y_train: {y_train.shape}\")\n",
        "    print(f\"X_test: {X_test.shape}\")\n",
        "    print(f\"y_test: {y_test.shape}\")\n",
        "\n",
        "    return ((X_train, y_train), (X_test, y_test))\n",
        "\n",
        "\n",
        "def save_model(model, filename):\n",
        "    with open(filename, \"wb\") as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "\n",
        "def load_model(filename):\n",
        "    with open(filename, \"rb\") as f:\n",
        "        model = pickle.load(f)\n",
        "    return model\n",
        "\n",
        "\n",
        "def pick(train_set, test_set, n_train, n_test):\n",
        "    images_train, y_train = train_set\n",
        "    images_test, y_test = test_set\n",
        "    train_set = images_train[:n_train], y_train[:n_train]\n",
        "    test_set = images_test[:n_test], y_test[:n_test]\n",
        "    return train_set, test_set\n",
        "\n",
        "\n",
        "def load_cifar():\n",
        "    train, test = get_cifar10(ndim=3)\n",
        "    return reshape_dataset(train, test)\n",
        "\n",
        "\n",
        "def load_mnist():\n",
        "    train, test = get_mnist(ndim=3)\n",
        "\n",
        "    X_train, y_train = train._datasets[0], train._datasets[1]\n",
        "    X_test, y_test = test._datasets[0], test._datasets[1]\n",
        "     \n",
        "    print(\"Dimensions of the original MNIST dataset---\")\n",
        "    print(f\"X_train: {X_train.shape}\")\n",
        "    print(f\"y_train: {y_train.shape}\")\n",
        "    print(f\"X_test: {X_test.shape}\")\n",
        "    print(f\"y_test: {y_test.shape}\")\n",
        "    \n",
        "    return reshape_dataset(train, test)\n",
        "\n",
        "\n",
        "def concatenate_dicts(*dicts):\n",
        "    \"\"\"Concatenate multiple directories into one\"\"\"\n",
        "    merged = []\n",
        "    for d in dicts:\n",
        "        merged += list(d.items())\n",
        "    return dict(merged)\n"
      ]
    }
  ]
}